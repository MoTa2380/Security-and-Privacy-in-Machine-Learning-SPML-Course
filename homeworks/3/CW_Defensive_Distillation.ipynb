{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mhpSyUYiXKug"
      },
      "source": [
        "**Name: Mohammad Taslmi**\n",
        "\n",
        "**Student Number: 99101321**\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K2djqmnzUe7j"
      },
      "source": [
        "In this notebook, you start by loading a trained Resnet model on CIFAR10 dataset. Then, you try to attack it with an $L_{2}$ C&W attack. Next, you work to make this model better at defending using defensive distillation, and test it against two different modes of $L_{2}$ C&W attacks again.\n",
        "\n",
        "It is recommended to use google colab to do this homework. You can connect to your drive using the code below to use it to save and load your trained models:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "3UxYLgBTS2yC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "87a4a5ed-7a3d-4226-c707-a91f38e50d22"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V-17Vzi99P3G"
      },
      "source": [
        "# Load CIFAR10 data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "4DQBtUQLudCD"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision.utils\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.models import resnet18\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "foD6o3tlum1d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "805e2b83-7e95-4f58-fd0e-bc64ae5a6635"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170498071/170498071 [00:03<00:00, 43594635.97it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "transform = transforms.Compose([transforms.ToTensor()])\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
        "                                        download=True, transform=transform)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
        "                                       download=True, transform=transform)\n",
        "\n",
        "batch_size = 128\n",
        "\n",
        "########################## Problem 1 (2  points) ###############################\n",
        "# todo: Define your data loaders for training and testing                      #\n",
        "################################################################################\n",
        "# your code goes here\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=False)\n",
        "################################ End ###########################################\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat',\n",
        "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
        "\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kXdawVZoGfJh"
      },
      "source": [
        "# Model set-up"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "vwYAOkLnrau_"
      },
      "outputs": [],
      "source": [
        "class resnet(nn.Module):\n",
        "  def __init__(self, num_cls, T=1):\n",
        "    super().__init__()\n",
        "    self.conv = nn.Sequential(\n",
        "        *list(resnet18(weights=None).children())[:-2])\n",
        "\n",
        "    self.fc = nn.Linear(512, num_cls)\n",
        "    self.temp = T\n",
        "\n",
        "  def forward(self, x, T=None):\n",
        "    if T is None:\n",
        "      T = self.temp\n",
        "    x = self.conv(x)\n",
        "    x = torch.flatten(x, start_dim=1)\n",
        "    logits = self.fc(x)\n",
        "    output = torch.softmax(logits / T, dim=1)\n",
        "\n",
        "    return logits, output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "hRQZtQCKyhtO"
      },
      "outputs": [],
      "source": [
        "def standard_train(model, loader, num_epoch, optimizer, criterion, device=device):\n",
        "    for epoch in range(num_epoch):\n",
        "      running_loss = 0.0\n",
        "      for i, data in enumerate(loader, 0):\n",
        "          inputs, labels = data[0].to(device), data[1].to(device)\n",
        "          optimizer.zero_grad()\n",
        "          outputs = model(inputs)\n",
        "          loss = criterion(outputs[1], labels)\n",
        "          loss.backward()\n",
        "          optimizer.step()\n",
        "          running_loss += loss.item()\n",
        "\n",
        "      print('Epoch %d loss: %.3f' % (epoch + 1, running_loss / len(trainloader)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "BvteE-DDJl8L",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a15fa649-be82-4beb-9f65-c8fc0f54b8a5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1KU4jWAwZIq0TUujAsgimLxGWUvwIEfyB\n",
            "From (redirected): https://drive.google.com/uc?id=1KU4jWAwZIq0TUujAsgimLxGWUvwIEfyB&confirm=t&uuid=7123454f-99d3-4046-aeee-e07f6d239a5b\n",
            "To: /content/resnet18_cifar10_model_pretrained.pth\n",
            "100% 44.8M/44.8M [00:00<00:00, 47.2MB/s]\n"
          ]
        }
      ],
      "source": [
        "# You don't need training here. just download trained weights of the Resnet18 model on CIFAR10 dataset\n",
        "!gdown 1KU4jWAwZIq0TUujAsgimLxGWUvwIEfyB"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "An3EFVR2maw1"
      },
      "outputs": [],
      "source": [
        "# load trained Resnet18 model on CIFAR10 dataset\n",
        "model = resnet(len(classes)).to(device)\n",
        "model_name = \"resnet18_cifar10_model_pretrained.pth\"\n",
        "model_PATH = \"/content/\" + model_name\n",
        "state_dict = torch.load(model_PATH, map_location=device)\n",
        "model.load_state_dict(state_dict)\n",
        "model = model.to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aPFQOzCXdm-c"
      },
      "source": [
        "# Computing clean accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "mHw1Z4KJduA9"
      },
      "outputs": [],
      "source": [
        "def standard_test(model, loader, device=device):\n",
        "  correct = 0\n",
        "  total = 0\n",
        "  ########################## Problem 2 (4 points) ##############################\n",
        "  # todo: Iterate over loader, compute the output and predicted                #\n",
        "  # label, and update \"correct\" and \"total\" counters accordingly.              #\n",
        "  ##############################################################################\n",
        "\n",
        "  # your code goes here\n",
        "  model.eval()\n",
        "  with torch.no_grad():\n",
        "    for i, data in enumerate(loader, 0):\n",
        "      inputs, labels = data[0].to(device), data[1].to(device)\n",
        "    outputs = model(inputs)\n",
        "    _, predicted = torch.max(outputs[1].data, 1)\n",
        "    total += labels.size(0)\n",
        "    correct += (predicted == labels).sum().item()\n",
        "\n",
        "  ################################ End #########################################\n",
        "  print(f'\\n Clean accuracy of the network on the 10000 test images: {100 * correct // total} %')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xiDPVF5BeI_D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "638b2c39-208f-48bb-ad62-381d6841a792"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Clean accuracy of the network on the 10000 test images: 75 %\n"
          ]
        }
      ],
      "source": [
        "standard_test(model, testloader)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ilLld2KN-UXG"
      },
      "source": [
        "# C&W L2 Attack on the base model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PiqsxXynerAQ"
      },
      "source": [
        "Note that for the sake of simplicity, you can ignore binary search for constant c for your implementation. However, implementing it would earn you a bonus!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "D6iOQ5i4fHvO"
      },
      "outputs": [],
      "source": [
        "def cw_l2_attack(model, image, label, mode='outputs', targeted=True, c=1e-4, kappa=0, max_iter=1000, learning_rate=0.01):\n",
        "\n",
        "    image = image.to(device)\n",
        "    label = label.to(device)\n",
        "    ######################### Problem 3 (8 points) #############################\n",
        "    # todo: Implement L2 C&W attack in the two following modes:                #\n",
        "    # 'outputs': use an f function which utilizes output probs of the model    #\n",
        "    # 'logits': use an f function which utilizes logits of the model           #\n",
        "    # Output of this function must be the resulting adversarial image.         #\n",
        "    ############################################################################\n",
        "\n",
        "    perturbation = torch.zeros_like(image, requires_grad=True)\n",
        "    optimizer = torch.optim.Adam([perturbation], lr=learning_rate)\n",
        "\n",
        "    num_classes = 10\n",
        "    target_label = (label + 1) % num_classes\n",
        "\n",
        "    for iteration in range(max_iter):\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        adv_image = (image + perturbation).clamp(0, 1)\n",
        "        logits, outputs = model(adv_image)\n",
        "\n",
        "        if (logits.argmax(1) == target_label).all():\n",
        "            break\n",
        "\n",
        "        if mode == 'logits':\n",
        "            logits_except_target = logits.clone()\n",
        "            logits_except_target[:, target_label] = float('-inf')  # Exclude the target class\n",
        "            f_x = logits_except_target.max(1)[0] - logits[:, target_label]\n",
        "        elif mode == 'outputs':\n",
        "            outputs_except_target = outputs.clone()\n",
        "            outputs_except_target[:, target_label] = float('-inf')  # Exclude the target class\n",
        "            f_x = outputs_except_target.max(1)[0] - outputs[:, target_label]\n",
        "\n",
        "\n",
        "        loss = torch.norm(perturbation) + c * torch.sum(torch.clamp(f_x, min=-kappa))\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "\n",
        "    adv_image = (image + perturbation).clamp(0, 1).detach()\n",
        "    return adv_image\n",
        "\n",
        "    ################################ End #######################################"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "pZ2pE6OxjIyy"
      },
      "outputs": [],
      "source": [
        "def attack_test(model, attack_model, loader, mode='outputs', targeted=True, c=0.1, kappa=0, device=device):\n",
        "  correct = 0\n",
        "  total = 0\n",
        "  ########################## Problem 4 (4 points) ##############################\n",
        "  # todo: Iterate over the FIRST batch of the loader                           #\n",
        "  # todo: Find an adversarial example by L2 C&W attack on attack_model         #\n",
        "  # todo: Compute the output and predicted label, and updated \"correct\" and    #\n",
        "  # \"total\" counters accordingly.                                              #\n",
        "  ##############################################################################\n",
        "\n",
        "  data_iter = iter(loader)\n",
        "  images, labels = next(data_iter)\n",
        "  images, labels = images.to(device), labels.to(device)\n",
        "  attack_model.eval()\n",
        "  model.eval()\n",
        "  for image, label in zip(images, labels):\n",
        "\n",
        "      adv_image = cw_l2_attack(attack_model, image.unsqueeze(0), label.unsqueeze(0), mode=mode, targeted=targeted, c=c, kappa=kappa)\n",
        "      logits, outputs = model(adv_image)\n",
        "      pred_label = logits.argmax(dim=1, keepdim=True)\n",
        "\n",
        "      correct += pred_label.eq(label.view_as(pred_label)).sum().item()\n",
        "      total += 1\n",
        "\n",
        "  ################################ End #########################################\n",
        "  print(f'\\n Accuracy of the network on the {total} test images of the first batch of testloader after attacking : {100 * correct // total} %')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IKF-S5Jklg_O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "80237dcc-aa75-49e3-ad86-682950a4b737"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "C&W L2 attack on the model using its outpus(probs):\n",
            "\n",
            " Accuracy of the network on the 128 test images of the first batch of testloader after attacking : 75 %\n",
            "\n",
            " C&W L2 attack on the model using its logits:\n",
            "\n",
            " Accuracy of the network on the 128 test images of the first batch of testloader after attacking : 0 %\n"
          ]
        }
      ],
      "source": [
        "print('C&W L2 attack on the model using its outpus(probs):')\n",
        "attack_test(model, model, testloader, mode='outputs', device=device)\n",
        "\n",
        "print('\\n C&W L2 attack on the model using its logits:')\n",
        "attack_test(model, model, testloader, mode='logits', device=device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XYpqaCNwj8X6"
      },
      "source": [
        "# Defensive distillation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TXso9K0DnLrK"
      },
      "source": [
        "## Teacher model training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "T1eUl9f4j_Mt"
      },
      "outputs": [],
      "source": [
        "T = 100\n",
        "teacher = resnet(len(classes), T=T).to(device)\n",
        "teacher_optim = optim.Adam(teacher.parameters(), lr=0.01)\n",
        "teacher_criterion = nn.CrossEntropyLoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "NyV1KEBDkayQ"
      },
      "outputs": [],
      "source": [
        "# load teacher model (if you already trained it)\n",
        "model_name = \"teacherModel.pth\"\n",
        "teacher_model_PATH = \"/content/drive/MyDrive/SPML_HW4_models/\" + model_name\n",
        "state_dict = torch.load(teacher_model_PATH)\n",
        "teacher.load_state_dict(state_dict)\n",
        "teacher = teacher.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S7p5sKb8kjXr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d57fcba7-9269-434f-8874-52dd0424fc7d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 loss: 1.605\n",
            "Epoch 2 loss: 1.598\n",
            "Epoch 3 loss: 1.594\n",
            "Epoch 4 loss: 1.589\n",
            "Epoch 5 loss: 1.585\n",
            "Epoch 6 loss: 1.579\n",
            "Epoch 7 loss: 1.576\n",
            "Epoch 8 loss: 1.574\n",
            "Epoch 9 loss: 1.572\n",
            "Epoch 10 loss: 1.570\n",
            "Epoch 11 loss: 1.568\n",
            "Epoch 12 loss: 1.566\n",
            "Epoch 13 loss: 1.566\n",
            "Epoch 14 loss: 1.564\n",
            "Epoch 15 loss: 1.561\n"
          ]
        }
      ],
      "source": [
        "teacher_optim = optim.Adam(teacher.parameters(), lr=0.001)\n",
        "standard_train(model=teacher,\n",
        "            loader=trainloader,\n",
        "            num_epoch=15,\n",
        "            optimizer=teacher_optim,\n",
        "            criterion=teacher_criterion,\n",
        "            device=device)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "standard_test(teacher, testloader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HrMxvGD9xjze",
        "outputId": "0fa7ec1f-d36c-40c1-a4e6-c003d38cc7d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Clean accuracy of the network on the 10000 test images: 76 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TaNnzhvbm4_a"
      },
      "outputs": [],
      "source": [
        "# save teacher model (only if you just trained it)\n",
        "teacher.eval()\n",
        "model_name = \"teacherModel.pth\"\n",
        "teacher_model_PATH = \"/content/drive/MyDrive/SPML_HW4_models/\" + model_name\n",
        "torch.save(teacher.state_dict(), teacher_model_PATH)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yetQZRHYnPJr"
      },
      "source": [
        "## Student model training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "9t69EQ9WnQpF"
      },
      "outputs": [],
      "source": [
        "def distillation(teacher, student, loader, num_epoch, optimizer, criterion, device=device):\n",
        "  ########################## Problem 5 (6 points) ##############################\n",
        "  # todo: Iterate over loader in each epoch                                    #\n",
        "  # todo: Compute MSE loss between student's logit and teacher's logit         #\n",
        "  # todo: Take a step by the optimizer                                         #\n",
        "  # todo: Monitor the training procedure                                       #\n",
        "  ##############################################################################\n",
        "\n",
        "  # your code goes here\n",
        "  for epoch in range(num_epoch):\n",
        "        running_loss = 0.0\n",
        "        for i, data in enumerate(loader, 0):\n",
        "            inputs, labels = data[0].to(device), data[1].to(device)\n",
        "            optimizer.zero_grad()\n",
        "            teacher_outputs, _ = teacher(inputs)\n",
        "            student_outputs, _ = student(inputs)\n",
        "            loss = criterion(student_outputs, teacher_outputs.detach())\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            running_loss += loss.item()\n",
        "\n",
        "        print('Epoch %d loss: %.3f' % (epoch + 1, running_loss / len(loader)))\n",
        "  ################################ End #########################################"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "ma5j_YhhnlF-"
      },
      "outputs": [],
      "source": [
        "T = 100\n",
        "student = resnet(len(classes), T=T).to(device)\n",
        "student_optim = optim.Adam(student.parameters(), lr=0.01)\n",
        "std_criterion = nn.MSELoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "UTUUWY8fnmi8"
      },
      "outputs": [],
      "source": [
        "# load student model (only if you already trained it)\n",
        "model_name = \"studentModel.pth\"\n",
        "student_model_PATH = \"/content/drive/MyDrive/SPML_HW4_models/\" + model_name\n",
        "state_dict = torch.load(student_model_PATH)\n",
        "student.load_state_dict(state_dict)\n",
        "student = student.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KDo7FSYAnzmv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dfba2e94-1b64-4a07-8997-a43c90eb7146"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 loss: 54667.581\n",
            "Epoch 2 loss: 51599.310\n",
            "Epoch 3 loss: 47246.446\n",
            "Epoch 4 loss: 44115.916\n",
            "Epoch 5 loss: 42639.867\n",
            "Epoch 6 loss: 39719.256\n",
            "Epoch 7 loss: 37999.535\n",
            "Epoch 8 loss: 34735.838\n",
            "Epoch 9 loss: 32176.859\n",
            "Epoch 10 loss: 33200.120\n",
            "Epoch 11 loss: 32074.436\n",
            "Epoch 12 loss: 30592.106\n",
            "Epoch 13 loss: 29186.152\n",
            "Epoch 14 loss: 26815.331\n",
            "Epoch 15 loss: 26768.282\n"
          ]
        }
      ],
      "source": [
        "student_optim = optim.Adam(student.parameters(), lr=0.001)\n",
        "distillation(teacher=teacher,\n",
        "             student=student,\n",
        "             loader=trainloader,\n",
        "             num_epoch=15,\n",
        "             optimizer=student_optim,\n",
        "             criterion=std_criterion,\n",
        "             device=device)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "standard_test(student, testloader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_qUe1jM62pai",
        "outputId": "1bb84aa8-4b6e-46c9-e3eb-f6ad8a376a70"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Clean accuracy of the network on the 10000 test images: 76 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7KK0cjx6n5LO"
      },
      "outputs": [],
      "source": [
        "# save student model (only if you just trained it)\n",
        "student.eval()\n",
        "model_name = \"studentModel.pth\"\n",
        "teacher_model_PATH = \"/content/drive/MyDrive/SPML_HW4_models/\" + model_name\n",
        "torch.save(student.state_dict(), teacher_model_PATH)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cB8T-Dq2pu9r"
      },
      "source": [
        "# C&W L2 Attack on the distilled  model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "6F9opcKwpHvQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dd83c925-e94e-454d-fcca-9fa3c08ac5e3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "C&W L2 attack on the student model using its outpus(probs):\n",
            "\n",
            " Accuracy of the network on the 128 test images of the first batch of testloader after attacking : 76 %\n",
            "\n",
            " C&W L2 attack on the student model using its logits:\n",
            "\n",
            " Accuracy of the network on the 128 test images of the first batch of testloader after attacking : 0 %\n"
          ]
        }
      ],
      "source": [
        "print('C&W L2 attack on the student model using its outpus(probs):')\n",
        "attack_test(student, student, testloader, mode='outputs', device=device)\n",
        "\n",
        "print('\\n C&W L2 attack on the student model using its logits:')\n",
        "attack_test(student, student, testloader, mode='logits', device=device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ge7pcN_sNBul"
      },
      "source": [
        "# Analyzing the results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lsudexRmNZll"
      },
      "source": [
        "Answer the following questions below them: (6 points)\n",
        "\n",
        "1.` Why do you think the attack success rate of the logits mode is generally better than the outputs(probs) mode?`\n",
        "\n",
        "**Answer**:\n",
        "\n",
        "I believe there are two reasons why the attack in logits mode performs better than in outputs mode.\n",
        "\n",
        "The first reason is that when the logits are large, the softmax function enters a saturation region, which may result in **gradient vanishing**.\n",
        "\n",
        "The second reason is that, given the same situation, the function $$f$$ in the output mode is significantly lower than that in the logits mode. This is because after applying the softmax function, the outputs range between 0 and 1 and their sum equals 1. In the scenario where $$c=0.1$$, the term $$c \\times f(x)$$ in the output mode is much smaller than that in the logits mode. Consequently, during the minimization process, the algorithm pays less attention to this term (which contributes to generating adversarial examples), making the attack less effective. As we can observe, when we use logits mode, the attack is 100% successful, but in the outputs mode, it's only 25% successful.\n",
        "\n",
        "\n",
        "2. `Why defensive distillation completely failed in the logits mode?`\n",
        "\n",
        "**Answer**:\n",
        "\n",
        "Defensive distillation fails in logits mode primarily because it is designed to smooth out the model's output layer, making it harder for an attacker to find adversarial examples. However, in logits mode, the attack operates on the layer before the softmax function, which is not smoothed by defensive distillation. Therefore, the attack can still effectively exploit the model's vulnerabilities.\n",
        "\n",
        "\n",
        "3. `As you have seen, defensive distillation is a mirage. Do you think that there is still some scenarios that this defense may be helpful?`\n",
        "\n",
        "**Answer**:\n",
        "\n",
        "While defensive distillation has been shown to be less effective than initially thought, it may still provide some level of protection in specific scenarios. For instance, it could potentially be useful against less sophisticated attacks or when used in combination with other defense mechanisms. However, it's important to note that relying solely on defensive distillation is not advisable due to its limitations."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}